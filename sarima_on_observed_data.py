# -*- coding: utf-8 -*-
"""SARIMA on observed data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10MyUkaVfd-ATnCan4oTeGFDwmM7EJwkh
"""

!pip install pmdarima

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import pandas as pd
import matplotlib.pylab
import matplotlib.pyplot as plt
from matplotlib.pylab import rcParams
rcParams['figure.figsize'] = 20, 16
import statsmodels.api as sm
import warnings
import itertools
warnings.filterwarnings("ignore") # ignore warning comments

df = pd.read_csv("/content/sample_data/ganga observerd data.csv")

df['Date_Observed'] = pd.to_datetime(df['Date_Observed'],infer_datetime_format=True) #convert from string to datetime
Dataset = df.set_index(['Date_Observed'])
Dataset.head(5)

df = Dataset

df.head()

df['streamfllow']

datetime = pd.date_range(start='1951-01-01', freq='MS',periods=len(df))

datetime

df['Month'] = datetime.month
df['Year'] = datetime.year

df.head()

df.dtypes

df.head()

import calendar
df['Month'] = df['Month'].apply(lambda x: calendar.month_abbr[x])
df.rename({'streamfllow':'df'},axis=1,inplace=True)
df = df[['Month','Year','df']]

df.head()

df['Date'] = datetime
df.set_index('Date',inplace=True)

plt.figure(figsize=(10,8))
df.groupby('Year')['df'].mean().plot(kind='bar')
plt.show()

plt.figure(figsize=(10,8))
df.groupby('Month')['df'].mean().reindex(index=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']).plot(kind='bar')
plt.show()

df_count = df['df']

plt.figure(figsize=(10,8))
df_count.plot()
plt.xlabel('Year')
plt.ylabel('Streamflow')
plt.show()

import statsmodels.api as sm

decompose_seasonality = sm.tsa.seasonal_decompose(df_count,model='additive',extrapolate_trend=8)

fig = decompose_seasonality.plot()
fig.set_figheight(10)
fig.set_figwidth(8)
fig.suptitle('Decomposition of Time Series')

#Trend
fig,axes = plt.subplots(2,2)
fig.set_figheight(10)
fig.set_figwidth(15)
axes[0][0].plot(df.index,df_count,label='Actual')
axes[0][0].plot(df.index,df_count.rolling(window=4).mean(),label='4 months rolling mean')
axes[0][0].set_xlabel('Year')
axes[0][0].set_ylabel('Streamflow')
axes[0][0].set_title('4 Months Rolling Mean')
axes[0][0].legend(loc='best')


axes[0][1].plot(df.index,df_count,label='Actual')
axes[0][1].plot(df.index,df_count.rolling(window=6).mean(),label='6 months rolling mean')
axes[0][1].set_xlabel('Year')
axes[0][1].set_ylabel('Streamflow')
axes[0][1].set_title('6 Months Rolling Mean')
axes[0][1].legend(loc='best')



axes[1][0].plot(df.index,df_count,label='Actual')
axes[1][0].plot(df.index,df_count.rolling(window=8).mean(),label='8 months rolling mean')
axes[1][0].set_xlabel('Year')
axes[1][0].set_ylabel('Streamflow')
axes[1][0].set_title('8 Months Rolling Mean')
axes[1][0].legend(loc='best')


axes[1][1].plot(df.index,df_count,label='Actual')
axes[1][1].plot(df.index,df_count.rolling(window=12).mean(),label='12 months rolling mean')
axes[1][1].set_xlabel('Year')
axes[1][1].set_ylabel('Streamflow')
axes[1][1].set_title('12 Months Rolling Mean')
axes[1][1].legend(loc='best')

plt.tight_layout()
plt.show()

#Seasonality
monthly_seasonality = pd.pivot_table(data=df,values='df',index='Month',columns='Year')
monthly_seasonality = monthly_seasonality.reindex(index=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])

monthly_seasonality

monthly_seasonality.plot(figsize=(8,6))
plt.show()

yearly_seasonality = pd.pivot_table(data=df,values='df',index='Year',columns='Month')
yearly_seasonality = yearly_seasonality[['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']]

yearly_seasonality

yearly_seasonality.plot(figsize=(8,6))
plt.show()

yearly_seasonality.plot(kind='box',figsize=(8,6))
plt.show()

#ARIMA Modelling
# Performing Dickey-Fuller test:
from statsmodels.tsa.stattools import adfuller
adfuller(df_count)

adfuller_results = pd.Series(adfuller(df_count)[:4],index=['T stats','p-value','lags used','Number of observations'])
for key,value in adfuller(df_count)[4].items():
    adfuller_results['Critical Value'+' '+ key] = value
print(adfuller_results)

df_count.plot()
plt.show()

df_log1 = np.log10(df_count)

df_log1.plot()
plt.show()

df_diff1 = df_count.diff(1)
df_diff1.head()

df_diff1.dropna(axis=0,inplace=True)

df_diff1.plot()
plt.show()

# Performing Dickey-Fuller test:
from statsmodels.tsa.stattools import adfuller
adfuller(df_diff1)
adfuller_results = pd.Series(adfuller(df_diff1)[:4],index=['T stats','p-value','lags used','Number of observations'])
for key,value in adfuller(df_diff1)[4].items():
    adfuller_results['Critical Value (%s)'%key] = value
print(adfuller_results)

log_diff1 = df_log1.diff(1)
log_diff1.head()

log_diff1.dropna(axis=0,inplace=True)

log_diff1.plot()
plt.show()

# Performing Dickey-Fuller test:
from statsmodels.tsa.stattools import adfuller
adfuller(log_diff1)
adfuller_results = pd.Series(adfuller(log_diff1)[:4],index=['T stats','p-value','lags used','Number of observations'])
for key,value in adfuller(log_diff1)[4].items():
    adfuller_results['Critical Value (%s)'%key] = value
print(adfuller_results)

log_diff2 = df_log1.diff(2)
log_diff2.head()

log_diff2.dropna(axis=0,inplace=True)

log_diff2.plot()
plt.show()

# Performing Dickey-Fuller test:
from statsmodels.tsa.stattools import adfuller
adfuller(log_diff2)
adfuller_results = pd.Series(adfuller(log_diff2)[:4],index=['T stats','p-value','lags used','Number of observations'])
for key,value in adfuller(log_diff2)[4].items():
    adfuller_results['Critical Value (%s)'%key] = value
print(adfuller_results)

#ARIMA Modeling
import itertools
# Define the p, d and q parameters to take any value between 0 and 2
p = q = range(0, 3)
d = range(0,1)
# Create all possible p, q, and d triplet pairings
pdq = list(itertools.product(p, d, q))

pdq

# Create all possible seasonal p, q, and d triplet pairings
D = range(0,3)
P = Q = range(0, 3) 
seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(P, D, Q))]

seasonal_pdq

import sys
warnings.filterwarnings("ignore") # specify to ignore warning messages

best_aic = np.inf
best_pdq = None
best_seasonal_pdq = None
temp_model = None

for param in pdq:
    for param_seasonal in seasonal_pdq:
       
        try:
            temp_model = sm.tsa.statespace.SARIMAX(log_diff2,
                                             order = param,
                                             seasonal_order = param_seasonal,
                                             enforce_stationarity=False,
                                             enforce_invertibility=False)
            results = temp_model.fit()

           # print("SARIMAX{}x{}12 - AIC:{}".format(param, param_seasonal, results.aic))
            if results.aic < best_aic:
                best_aic = results.aic
                best_pdq = param
                best_seasonal_pdq = param_seasonal
        except:
          #print("Unexpected error:", sys.exc_info()[0])
            continue
print("Best SARIMAX{}x{}12 model - AIC:{}".format(best_pdq, best_seasonal_pdq, best_aic))

#Best fit ARIMA model
sarima = sm.tsa.statespace.SARIMAX(log_diff2,order=(1,0,1),seasonal_order=(1,0,1,12),enforce_invertibility=False,enforce_stationarity=False)

sarima_results = sarima.fit()

print(sarima_results.summary())

df_count.tail(15)

obs_prediction = sarima_results.get_prediction(start=pd.to_datetime('1951-03-01'), full_results=True)

obs_prediction.predicted_mean

predicted_values = np.power(10,obs_prediction.predicted_mean)

predicted_values

actual_values = df_count['1973-01-01':]

actual_values

# mean absolute percentage error
mape = np.mean(np.abs(actual_values - predicted_values)/actual_values)
mape

# mean square error
mse = np.mean((actual_values - predicted_values) ** 2)
mse

# Get future forecast 276 steps (23 years) ahead 
n_steps = 276
pred_uc_99 = sarima_results.get_forecast(steps=276, alpha=0.01) # alpha=0.01 signifies 99% confidence interval
pred_uc_95 = sarima_results.get_forecast(steps=276, alpha=0.05) # alpha=0.05 95% CI

# Get confidence intervals 95% & 99% of the forecasts
pred_ci_99 = pred_uc_99.conf_int()
pred_ci_95 = pred_uc_95.conf_int()

pred_ci_99.head()

pred_ci_95.head()

n_steps = 276
idx = pd.date_range(df_count.index[-1], periods=n_steps, freq='MS')
fc_95 = pd.DataFrame(np.column_stack([np.power(10, pred_uc_95.predicted_mean), np.power(10, pred_ci_95)]), 
                     index=idx, columns=['forecast', 'lower_ci_95', 'upper_ci_95'])
fc_99 = pd.DataFrame(np.column_stack([np.power(10, pred_ci_99)]), 
                     index=idx, columns=['lower_ci_99', 'upper_ci_99'])

fc_95.head()

fc_99.head()

fc_all = fc_95.combine_first(fc_99)
fc_all = fc_all[['forecast', 'lower_ci_95', 'upper_ci_95', 'lower_ci_99', 'upper_ci_99']] # columns reordering 
fc_all.head()

# plot the prediction along with the confidence band
axis = df_count.plot(label='Observed', figsize=(15, 6))
fc_all['forecast'].plot(ax=axis, label='Forecast', alpha=0.7)
axis.fill_between(fc_all.index, fc_all['lower_ci_99'], fc_all['upper_ci_99'], color='k', alpha=.25)
axis.set_xlabel('Years')
axis.set_ylabel('Streamflow')
plt.legend(loc='best')
plt.show()

#Diagnostics
sarima_results.plot_diagnostics(lags=30,figsize=(10,8))

model26 = fc_all['forecast']

model26.columns =['Date', 'forecast']
  
# displaying the future predicted values
print(model26)